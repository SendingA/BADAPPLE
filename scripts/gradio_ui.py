import gradio as gr
import os
import json
import subprocess
import sys
from pathlib import Path
import pandas as pd
import asyncio

# æ·»åŠ å½“å‰ç›®å½•å’Œ scripts ç›®å½•åˆ° Python è·¯å¾„
project_dir = Path(__file__).parent.parent
scripts_dir = project_dir / "scripts"
sys.path.append(str(project_dir))
sys.path.append(str(scripts_dir))

gr.set_static_paths([str(project_dir)])

# å¯¼å…¥å„ä¸ªæ­¥éª¤çš„æ¨¡å—
try:
    import gradio_utils.step0
    import gradio_utils.step1
    import gradio_utils.step2
    
    from step3_txt_to_voice_kokoro import main as step3_main
    from step4_output_video import main as step4_main
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰è„šæœ¬æ–‡ä»¶å­˜åœ¨äº scripts ç›®å½•ä¸­")


def run_step3(input_file, output_dir, language, gender):
    """æ‰§è¡Œ Step 3: æ–‡æœ¬è½¬è¯­éŸ³"""
    try:
        # å‡†å¤‡å‚æ•°
        input_file = input_file or str(project_dir / "scripts" / "åœºæ™¯åˆ†å‰².json")
        output_dir = output_dir or str(project_dir / "voice")
        
        success, audio_files = step3_main(input_file, output_dir, language, gender)
        
        if success and audio_files:
            # è¿”å›ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ç”¨äºé¢„è§ˆï¼Œä»¥åŠæ‰€æœ‰æ–‡ä»¶çš„ä¿¡æ¯
            first_audio = audio_files[0] if audio_files else None
            result_text = f"âœ… Step 3 å®Œæˆï¼šæˆåŠŸç”Ÿæˆ {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\n"
            result_text += "ç”Ÿæˆçš„æ–‡ä»¶:\n"
            for i, file_path in enumerate(audio_files):
                result_text += f"  {i+1}. {os.path.basename(file_path)}\n"
            
            return result_text, first_audio, audio_files
        else:
            return "âŒ Step 3 å¤±è´¥: æœªç”ŸæˆéŸ³é¢‘æ–‡ä»¶", None, []
        
    except Exception as e:
        return f"âŒ Step 3 å¤±è´¥: {str(e)}", None, []

def load_existing_audio(voice_dir):
    """åŠ è½½ç°æœ‰çš„éŸ³é¢‘æ–‡ä»¶"""
    try:
        voice_dir = voice_dir or str(project_dir / "voice")
        
        if not os.path.exists(voice_dir):
            return "âŒ éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨", None, []
        
        # æŸ¥æ‰¾æ‰€æœ‰ .wav æ–‡ä»¶
        audio_files = []
        for file in os.listdir(voice_dir):
            if file.lower().endswith('.wav'):
                audio_files.append(os.path.join(voice_dir, file))
        
        # æŒ‰æ–‡ä»¶åæ’åº
        audio_files.sort()
        
        if not audio_files:
            return "âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶", None, []
        
        # è¿”å›ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ç”¨äºé¢„è§ˆ
        first_audio = audio_files[0]
        result_text = f"âœ… æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\n"
        result_text += "ç°æœ‰æ–‡ä»¶:\n"
        for i, file_path in enumerate(audio_files):
            result_text += f"  {i+1}. {os.path.basename(file_path)}\n"
        
        return result_text, first_audio, audio_files
        
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}", None, []

def preview_audio(audio_files, selected_index):
    """é¢„è§ˆé€‰ä¸­çš„éŸ³é¢‘æ–‡ä»¶"""
    try:
        if audio_files and 0 <= selected_index < len(audio_files):
            return audio_files[selected_index]
        return None
    except:
        return None

def run_step4(fps, enlarge_background, enable_effect, effect_type):
    """æ‰§è¡Œ Step 4: è¾“å‡ºè§†é¢‘"""
    try:
        # æ›´æ–°é…ç½®
        config_path = project_dir / "config.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            config.update({
                "fps": fps,
                "enlarge_background": enlarge_background,
                "enable_effect": enable_effect,
                "effect_type": effect_type
            })
            
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        
        result = step4_main()
        return "âœ… Step 4 å®Œæˆï¼šè§†é¢‘ç”Ÿæˆå®Œæˆ"
        
    except Exception as e:
        return f"âŒ Step 4 å¤±è´¥: {str(e)}"

def run_all_steps(novel_text, api_key, server_urls_text, max_workers, min_sentence_length, width, height, steps, fps):
    """ä¸€é”®è¿è¡Œæ‰€æœ‰æ­¥éª¤ï¼ˆæ”¯æŒå¤šæœåŠ¡å™¨ï¼‰"""
    results = []
    
    # Step 0
    result0, chars, scenarios = gradio_utils.step0.run_step0(novel_text, "", api_key)
    results.append(f"Step 0: {result0}")
    
    if "å¤±è´¥" in result0:
        return "\n".join(results)
    
    # Step 1
    result1, _ = gradio_utils.step1.run_step1(min_sentence_length, "", api_key)
    results.append(f"Step 1: {result1}")
    
    if "å¤±è´¥" in result1:
        return "\n".join(results)
    
    # Step 2 (å¤šæœåŠ¡å™¨)
    result2, _ = gradio_utils.step2.run_step2(
        server_urls_text, max_workers, width, height, steps, "DPM++ 3M SDE", 
        "Karras", 7, -1, True, 2, "Latent", 0.7, "", "", None
    )
    results.append(f"Step 2: {result2}")
    
    if "å¤±è´¥" in result2:
        return "\n".join(results)
    
    # Step 3
    result3, _, _ = run_step3("", "", "zh", "zf")
    results.append(f"Step 3: {result3}")
    
    if "å¤±è´¥" in result3:
        return "\n".join(results)
    
    # Step 4
    result4 = run_step4(fps, True, True, 0)
    results.append(f"Step 4: {result4}")
    


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="å°è¯´è½¬è§†é¢‘ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¬ å°è¯´è½¬è§†é¢‘ç”Ÿæˆå™¨")
    gr.Markdown("å°†å°è¯´æ–‡æœ¬è½¬æ¢ä¸ºå¸¦é…éŸ³çš„è§†é¢‘ï¼Œæ”¯æŒè§’è‰²è¯†åˆ«ã€å›¾åƒç”Ÿæˆã€è¯­éŸ³åˆæˆç­‰åŠŸèƒ½")
    
    with gr.Tabs():
        # åœ¨ä¸€é”®ç”Ÿæˆç•Œé¢ä¸­æ·»åŠ å¤šæœåŠ¡å™¨é…ç½®
        with gr.TabItem("ğŸš€ ä¸€é”®ç”Ÿæˆ"):
            gr.Markdown("### å¿«é€Ÿç”Ÿæˆæ¨¡å¼ï¼ˆæ”¯æŒå¤šæœåŠ¡å™¨å¹¶è¡Œï¼‰")
            
            with gr.Row():
                with gr.Column():
                    quick_novel_text = gr.Textbox(
                        label="å°è¯´æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥å®Œæ•´çš„å°è¯´å†…å®¹...",
                        lines=10
                    )
                    quick_api_key = gr.Textbox(
                        label="OpenAI API Key",
                        placeholder="sk-...",
                        type="password"
                    )
                    quick_server_urls = gr.Textbox(
                        label="WebUI æœåŠ¡å™¨åœ°å€ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        value="http://172.18.36.54:7862\nhttp://172.18.36.54:7863\nhttp://172.18.36.54:7864\nhttp://172.18.36.54:7865\nhttp://172.18.36.54:7866",
                        placeholder="http://server1:7860\nhttp://server2:7861",
                        lines=3
                    )
                    quick_max_workers = gr.Number(
                        label="æœ€å¤§å¹¶è¡Œæ•°",
                        value=2,
                        minimum=1,
                        maximum=8
                    )
                    
                with gr.Column():
                    quick_min_length = gr.Slider(
                        label="æœ€å°å¥å­é•¿åº¦",
                        minimum=50,
                        maximum=200,
                        value=100,
                        step=10
                    )
                    quick_width = gr.Number(label="å›¾åƒå®½åº¦", value=512)
                    quick_height = gr.Number(label="å›¾åƒé«˜åº¦", value=512)
                    quick_steps = gr.Slider(label="ç”Ÿæˆæ­¥æ•°", minimum=10, maximum=100, value=50)
                    quick_fps = gr.Slider(label="è§†é¢‘å¸§ç‡", minimum=15, maximum=60, value=30)
            
            quick_run_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", size="lg")
            quick_output = gr.Textbox(label="æ‰§è¡Œç»“æœ", lines=5)
            
            quick_run_btn.click(
                fn=run_all_steps,
                inputs=[quick_novel_text, quick_api_key, quick_server_urls, quick_max_workers,
                    quick_min_length, quick_width, quick_height, quick_steps, quick_fps],
                outputs=quick_output
            )

        
        # Step 0 æ ‡ç­¾é¡µ
        gradio_utils.step0.create_interface()
  
        # Step 1 æ ‡ç­¾é¡µ
        gradio_utils.step1.create_interface()

        # Step 2 æ ‡ç­¾é¡µ
        gradio_utils.step2.create_interface()
        
        # Step 3 æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸµ Step 3: è¯­éŸ³åˆæˆ"):
            gr.Markdown("### ä¸ºåœºæ™¯ç”Ÿæˆé…éŸ³")
            
            with gr.Row():
                with gr.Column():
                    step3_input_file = gr.Textbox(
                        label="è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                        placeholder="é»˜è®¤: ../scripts/åœºæ™¯åˆ†å‰².json"
                    )
                    step3_output_dir = gr.Textbox(
                        label="è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰",
                        placeholder="é»˜è®¤: ../voice"
                    )
                    step3_language = gr.Dropdown(
                        label="è¯­è¨€",
                        choices=["zh", "en"],
                        value="zh"
                    )
                    step3_gender = gr.Radio(
                        label="å£°éŸ³æ€§åˆ«",
                        choices=[("å¥³å£°", "zf"), ("ç”·å£°", "zm")],
                        value="zf"
                    )
                    
                    with gr.Row():
                        step3_btn = gr.Button("ğŸ¤ ç”Ÿæˆè¯­éŸ³", variant="primary")
                        step3_load_btn = gr.Button("ğŸ“ åŠ è½½ç°æœ‰éŸ³é¢‘", variant="secondary")
                
                with gr.Column():
                    step3_output = gr.Textbox(label="æ‰§è¡Œç»“æœ", lines=8)
                    
                    # éŸ³é¢‘é¢„è§ˆåŒºåŸŸ
                    gr.Markdown("### ğŸµ éŸ³é¢‘é¢„è§ˆ")
                    step3_audio_preview = gr.Audio(
                        label="éŸ³é¢‘é¢„è§ˆ",
                        type="filepath",
                        interactive=False
                    )
                    
                    # éŸ³é¢‘æ–‡ä»¶é€‰æ‹©
                    step3_audio_selector = gr.Slider(
                        label="é€‰æ‹©éŸ³é¢‘æ–‡ä»¶ï¼ˆ1å¼€å§‹ï¼‰",
                        minimum=1,
                        maximum=10,
                        value=1,
                        step=1,
                        visible=False
                    )
                    
                    # éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º
                    with gr.Row():
                        step3_current_file = gr.Textbox(
                            label="å½“å‰æ–‡ä»¶",
                            interactive=False,
                            visible=False
                        )
            
            # éšè—çš„çŠ¶æ€å˜é‡ç”¨äºå­˜å‚¨éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
            step3_audio_files = gr.State([])
            
            # ç”Ÿæˆè¯­éŸ³æŒ‰é’®çš„å›è°ƒ
            step3_btn.click(
                fn=run_step3,
                inputs=[step3_input_file, step3_output_dir, step3_language, step3_gender],
                outputs=[step3_output, step3_audio_preview, step3_audio_files]
            ).then(
                fn=lambda files: [
                    gr.update(
                        visible=len(files) > 1,
                        maximum=len(files) if files else 1,
                        value=1
                    ),
                    gr.update(
                        value=os.path.basename(files[0]) if files else "",
                        visible=len(files) > 0
                    )
                ],
                inputs=[step3_audio_files],
                outputs=[step3_audio_selector, step3_current_file]
            )
            
            # åŠ è½½ç°æœ‰éŸ³é¢‘æŒ‰é’®çš„å›è°ƒ
            step3_load_btn.click(
                fn=load_existing_audio,
                inputs=[step3_output_dir],
                outputs=[step3_output, step3_audio_preview, step3_audio_files]
            ).then(
                fn=lambda files: [
                    gr.update(
                        visible=len(files) > 1,
                        maximum=len(files) if files else 1,
                        value=1
                    ),
                    gr.update(
                        value=os.path.basename(files[0]) if files else "",
                        visible=len(files) > 0
                    )
                ],
                inputs=[step3_audio_files],
                outputs=[step3_audio_selector, step3_current_file]
            )
            
            # éŸ³é¢‘é€‰æ‹©å™¨çš„å›è°ƒ
            step3_audio_selector.change(
                fn=lambda files, idx: [
                    preview_audio(files, int(idx)-1) if files else None,
                    os.path.basename(files[int(idx)-1]) if files and 0 <= int(idx)-1 < len(files) else ""
                ],
                inputs=[step3_audio_files, step3_audio_selector],
                outputs=[step3_audio_preview, step3_current_file]
            )
        
        # Step 4 æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸ¬ Step 4: è§†é¢‘è¾“å‡º"):
            gr.Markdown("### åˆæˆæœ€ç»ˆè§†é¢‘")
            
            with gr.Row():
                with gr.Column():
                    step4_fps = gr.Slider(
                        label="è§†é¢‘å¸§ç‡",
                        minimum=15,
                        maximum=60,
                        value=30,
                        step=1
                    )
                    step4_enlarge = gr.Checkbox(
                        label="æ”¾å¤§èƒŒæ™¯",
                        value=True
                    )
                    step4_enable_effect = gr.Checkbox(
                        label="å¯ç”¨ç‰¹æ•ˆ",
                        value=True
                    )
                    step4_effect_type = gr.Dropdown(
                        label="ç‰¹æ•ˆç±»å‹",
                        choices=[("Ken Burns", 0), ("æ·¡å…¥æ·¡å‡º", 1)],
                        value=0
                    )
                
                with gr.Column():
                    step4_output = gr.Textbox(label="æ‰§è¡Œç»“æœ", lines=10)
            
            step4_btn = gr.Button("æ‰§è¡Œ Step 4", variant="secondary")
            step4_btn.click(
                fn=run_step4,
                inputs=[step4_fps, step4_enlarge, step4_enable_effect, step4_effect_type],
                outputs=step4_output
            )
        
        # å¸®åŠ©æ ‡ç­¾é¡µ
        with gr.TabItem("â“ ä½¿ç”¨è¯´æ˜"):
            gr.Markdown("""
            ## ä½¿ç”¨æµç¨‹
            
            ### ğŸš€ ä¸€é”®ç”Ÿæˆï¼ˆæ¨èæ–°æ‰‹ï¼‰
            1. åœ¨ã€Œä¸€é”®ç”Ÿæˆã€é¡µé¢è¾“å…¥å°è¯´æ–‡æœ¬å’Œå¿…è¦å‚æ•°
            2. ç‚¹å‡»ã€Œå¼€å§‹ç”Ÿæˆã€ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å®Œæˆæ‰€æœ‰æ­¥éª¤
            3. ç­‰å¾…å¤„ç†å®Œæˆï¼Œæœ€ç»ˆè§†é¢‘å°†ä¿å­˜åœ¨ `../video` ç›®å½•
            
            ### ğŸ”§ åˆ†æ­¥éª¤æ‰§è¡Œï¼ˆé«˜çº§ç”¨æˆ·ï¼‰
            1. **Step 0**: è¾“å…¥å°è¯´å…¨æ–‡ï¼Œç”Ÿæˆè§’è‰²å­—å…¸
            2. **Step 1**: æå–å…³é”®è¯ï¼Œç”Ÿæˆ AI ç»˜å›¾æç¤ºè¯
            3. **Step 2**: æ ¹æ®æç¤ºè¯ç”Ÿæˆåœºæ™¯å›¾åƒ
            4. **Step 3**: ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆé…éŸ³
            5. **Step 4**: åˆæˆæœ€ç»ˆè§†é¢‘
            
            ## æ³¨æ„äº‹é¡¹
            
            - **API Key**: éœ€è¦æœ‰æ•ˆçš„ OpenAI API Key ç”¨äºæ–‡æœ¬åˆ†æ
            - **WebUI**: Step 2 éœ€è¦è¿è¡Œ Automatic1111 WebUI æœåŠ¡
            - **è¯­éŸ³**: Step 3 éœ€è¦ Kokoro TTS æ¨¡å‹æ–‡ä»¶
            - **æ–‡ä»¶è·¯å¾„**: ç¡®ä¿ç›¸å…³ç›®å½•å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™
            
            ## ç³»ç»Ÿè¦æ±‚
            
            - Python 3.8+
            - è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆå›¾åƒå’Œè§†é¢‘æ–‡ä»¶è¾ƒå¤§ï¼‰
            - ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼ˆAPI è°ƒç”¨ï¼‰
            - CUDA å…¼å®¹æ˜¾å¡ï¼ˆæ¨èï¼‰
            """)

if __name__ == "__main__":
    
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7870,
        share=False,
        debug=True,
        allowed_paths=[
            str(project_dir), 
            str(scripts_dir),
            str(Path(project_dir) / "image"),
            str(Path(project_dir) / "temp"),
            str(Path(project_dir) / "voice"),
            str(Path(project_dir) / "video")
        ]
        
    )